{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.realpath(\"..\"))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from evlp_bronch.dataset import ALL_LUNG_IDS, RawEVLPDataset, ProcessedEVLPDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2676d379610>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(seed):   \n",
    "    train_lung_ids, test_lung_ids = train_test_split(\n",
    "    ALL_LUNG_IDS, test_size=2, random_state=seed\n",
    "    )\n",
    "    train_lung_ids, val_lung_ids = train_test_split(\n",
    "    train_lung_ids, test_size=2, random_state=seed\n",
    "    )\n",
    "\n",
    "    train_dataset = ProcessedEVLPDataset(train_lung_ids)\n",
    "    val_dataset = ProcessedEVLPDataset(val_lung_ids)\n",
    "    test_dataset = ProcessedEVLPDataset(test_lung_ids)\n",
    "    print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 22:04:21,045 - evlp_bronch.dataset - INFO - Lung_id 29: Interpolation Dy_comp: between 329 and 331: 142.764474, 157.684626\n",
      "2023-12-04 22:04:21,100 - evlp_bronch.dataset - INFO - Lung_id 47: Interpolation Dy_comp: between 51 and 56: 50.582276, 72.674668\n",
      "2023-12-04 22:04:21,121 - evlp_bronch.dataset - INFO - Lung_id 53: Interpolation Dy_comp: between 2813 and 2824: 60.586801, 106.632301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 7 4\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = load_data(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_last(lst, value): # find the last occurence of a value in a list\n",
    "    lst.reverse()\n",
    "    i = lst.index(value)\n",
    "    lst.reverse()\n",
    "    return len(lst) - i - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_pad_sequence(sequence, target_length):\n",
    "    current_length = len(sequence)\n",
    "    total_padding = target_length - current_length\n",
    "    if total_padding <= 0:\n",
    "        return sequence\n",
    "    pad_after = total_padding\n",
    "\n",
    "    return np.pad(sequence, (0, pad_after), mode='edge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1416"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_max_length_x():\n",
    "    m = [0,0,0]\n",
    "    for i in train_dataset:\n",
    "        metric_start = find_last(list(i['Is_bronch']), 1) # find the last bronch\n",
    "        if metric_start > m[0]:\n",
    "            m[0]=metric_start+1\n",
    "    for i in val_dataset:\n",
    "        metric_start = find_last(list(i['Is_bronch']), 1) # find the last bronch\n",
    "        if metric_start > m[1]:\n",
    "            m[1]=metric_start+1\n",
    "    for i in test_dataset:\n",
    "        metric_start = find_last(list(i['Is_bronch']), 1) # find the last bronch\n",
    "        if metric_start > m[2]:\n",
    "            m[2]=metric_start+1\n",
    "    return max(m)\n",
    "max_l = find_max_length_x()\n",
    "max_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_max_length_y(dataset):\n",
    "    m = 0\n",
    "    for i in dataset:\n",
    "        metric_start = find_last(list(i['Is_bronch']), 1) # find the last bronch\n",
    "        changes = np.where(np.diff(i['Is_assessment']) == 1)[0]  # Find where each assessment period begins\n",
    "        # Find the first assessment period that starts after the last bronch occurrence\n",
    "        first_assessment_after_bronch = None\n",
    "        for change in changes:\n",
    "            if change > metric_start:\n",
    "                first_assessment_after_bronch = change\n",
    "                break\n",
    "        if metric_start< (len(i['Is_assessment']) - 1) * 0:\n",
    "            continue\n",
    "        if first_assessment_after_bronch is None:\n",
    "            first_assessment_after_bronch = len(i['Is_assessment']) - 1\n",
    "        if len(i['Dy_comp'][metric_start:first_assessment_after_bronch]) == 0: # if bronch紧接着assessment\n",
    "            continue\n",
    "        if len(i['Dy_comp'][metric_start:first_assessment_after_bronch]) > m:\n",
    "            m = first_assessment_after_bronch - metric_start\n",
    "    return m + 1\n",
    "max_y_train = find_max_length_y(train_dataset)\n",
    "max_y_val = find_max_length_y(val_dataset)\n",
    "max_y_test = find_max_length_y(test_dataset)\n",
    "max_y = max(max_y_train, max_y_val, max_y_test)\n",
    "max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dataset(dataset):\n",
    "    X_dc = []\n",
    "    X_is_normal = []\n",
    "    X_is_bronch = []\n",
    "\n",
    "    Y = []\n",
    "    Y_len = []\n",
    "\n",
    "    for i in dataset:\n",
    "        metric_start = find_last(list(i['Is_bronch']), 1) # find the last bronch\n",
    "        changes = np.where(np.diff(i['Is_assessment']) == 1)[0]  # Find where each assessment period begins\n",
    "        # Find the first assessment period that starts after the last bronch occurrence\n",
    "        first_assessment_after_bronch = None\n",
    "        for change in changes:\n",
    "            if change > metric_start:\n",
    "                first_assessment_after_bronch = change\n",
    "                break\n",
    "        if metric_start< (len(i['Is_assessment']) - 1) * 0:\n",
    "            continue\n",
    "\n",
    "        if first_assessment_after_bronch is None:\n",
    "            first_assessment_after_bronch = len(i['Is_assessment']) - 1\n",
    "        if len(i['Dy_comp'][metric_start:first_assessment_after_bronch]) == 0: # if bronch紧接着assessment\n",
    "            continue\n",
    "\n",
    "        # 做padding，保证长度一致，用最长的长度\n",
    "        X_dc.append(right_pad_sequence(i['Dy_comp'][:metric_start+1], max_l))\n",
    "        X_is_normal.append(right_pad_sequence(i['Is_normal'][:metric_start+1], max_l))\n",
    "        X_is_bronch.append(right_pad_sequence(i['Is_bronch'][:metric_start+1], max_l))\n",
    "\n",
    "        Y_len.append(len(i['Dy_comp'][metric_start:first_assessment_after_bronch])) # 记录长度，用于计算loss)\n",
    "        Y.append(right_pad_sequence(i['Dy_comp'][metric_start:first_assessment_after_bronch], max_y))\n",
    "\n",
    "    print(f\"length is {len(X_dc)}\")    \n",
    "    assert len(X_dc) == len(X_is_bronch) == len(X_is_normal) == len(Y), \"Inconsistent number of samples\"\n",
    "\n",
    "    X_dc = np.array(X_dc).reshape(-1, max_l)\n",
    "    X_is_normal = np.array(X_is_normal).reshape(-1, max_l)\n",
    "    X_is_bronch = np.array(X_is_bronch).reshape(-1, max_l)\n",
    "    Y = torch.from_numpy(np.array(Y)).float()\n",
    "    Y_len = torch.from_numpy(np.array(Y_len)).int()\n",
    "\n",
    "    X_combined = np.stack([X_dc, X_is_normal, X_is_bronch], axis=1)  # Shape becomes [N, 3, 1470]\n",
    "    X_combined = torch.from_numpy(X_combined).float()\n",
    "\n",
    "    return X_combined, Y, Y_len\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EVLPDataset(Dataset):\n",
    "    def __init__(self, X_combined, Y, Y_len):\n",
    "        self.X_combined = X_combined\n",
    "        self.Y = Y\n",
    "        self.Y_len = Y_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_combined[idx], self.Y[idx], self.Y_len[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length is 143\n",
      "length is 7\n",
      "length is 4\n"
     ]
    }
   ],
   "source": [
    "x_combine_train, y_train, y_len_train = set_dataset(train_dataset)\n",
    "x_combine_val, y_val, y_len_val = set_dataset(val_dataset)\n",
    "x_combine_test, y_test, y_len_test = set_dataset(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(EVLPDataset(x_combine_train, y_train, y_len_train), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(EVLPDataset(x_combine_val, y_val, y_len_val), batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(EVLPDataset(x_combine_test, y_test, y_len_test), batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, test_loader, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []  # List to store average training loss per epoch\n",
    "    val_losses = []    # List to store average validation loss per epoch\n",
    "\n",
    "    val_target = []\n",
    "    val_predict = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, y, lengths in train_loader:\n",
    "            inputs, y = inputs.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            mask = torch.arange(outputs.size(1)).expand(len(lengths), outputs.size(1)) < lengths.unsqueeze(1)\n",
    "            mask = mask.to(device)\n",
    "            outputs_masked = torch.masked_select(outputs, mask).to(device)\n",
    "            y_masked = torch.masked_select(y, mask).to(device)\n",
    "\n",
    "            loss = criterion(outputs_masked, y_masked)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        average_loss = running_loss / len(train_loader)\n",
    "        epoch_losses.append(average_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            running_val_loss = 0.0\n",
    "            for inputs, y, lengths in val_loader:\n",
    "                inputs, y = inputs.to(device), y.to(device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                mask = torch.arange(outputs.size(1)).expand(len(lengths), outputs.size(1)) < lengths.unsqueeze(1)\n",
    "                mask = mask.to(device)\n",
    "                outputs_masked = torch.masked_select(outputs, mask).to(device)\n",
    "                y_masked = torch.masked_select(y, mask).to(device)\n",
    "\n",
    "                loss = criterion(outputs_masked, y_masked)\n",
    "\n",
    "                val_loss = criterion(outputs_masked, y_masked)\n",
    "            \n",
    "                if epoch == epochs - 1:\n",
    "                    val_target.append(y[:, :lengths])\n",
    "                    val_predict.append(outputs[:, :lengths])\n",
    "    \n",
    "                running_val_loss += val_loss.item()\n",
    "\n",
    "            average_val_loss = running_val_loss / len(val_loader)\n",
    "            val_losses.append(average_val_loss)\n",
    "\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Training Loss: {average_loss}, Validation Loss: {average_val_loss}\")\n",
    "\n",
    "        if epoch == epochs - 1:\n",
    "            # Flatten the validation target and prediction lists\n",
    "            flat_val_target = torch.cat([t.flatten() for t in val_target])\n",
    "            flat_val_predict = torch.cat([p.flatten() for p in val_predict])\n",
    "\n",
    "            # Calculate Pearson's R\n",
    "            pearson_r, _ = pearsonr(flat_val_target.cpu().numpy(), flat_val_predict.cpu().numpy())\n",
    "            print(f\"Epoch {epoch + 1}, Pearson's R: {pearson_r}\")\n",
    "\n",
    "        model.train()\n",
    "\n",
    "    # Determine the number of rows and columns for subplots\n",
    "    num_samples = len(val_predict)\n",
    "    cols = 2\n",
    "    rows = num_samples // cols + (num_samples % cols > 0)\n",
    "\n",
    "    # # Plotting\n",
    "    # plt.figure(figsize=(12, 4 * rows))\n",
    "    # for i in range(num_samples):\n",
    "    #     plt.subplot(rows, cols, i + 1)\n",
    "    #     plt.plot(val_predict[i][0].cpu().numpy(), label='Predicted')\n",
    "    #     plt.plot(val_target[i][0].cpu().numpy(), label='Target', alpha=0.7)\n",
    "    #     plt.title(f\"Sample {i+1}\")\n",
    "    #     plt.xlabel(\"Time Steps\")\n",
    "    #     plt.ylabel(\"Values\")\n",
    "    #     plt.legend()\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.figure(figsize=(7, 4))\n",
    "    # plt.plot(range(1, epochs+1), epoch_losses, marker='o', color='blue', label='Training Loss')\n",
    "    # plt.plot(range(1, epochs+1), val_losses, marker='o', color='red', label='Validation Loss')\n",
    "    # plt.title('Training and Validation Loss per Epoch')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.grid(True)\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    output_ls = []\n",
    "    target_ls = []\n",
    "\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, y, lengths in test_loader:\n",
    "            data, y = data.to(device), y.to(device)\n",
    "            outputs = model(data)\n",
    "            \n",
    "            mask = torch.arange(outputs.size(1)).expand(len(lengths), outputs.size(1)) < lengths.unsqueeze(1)\n",
    "            mask = mask.to(device)\n",
    "            outputs_masked = torch.masked_select(outputs, mask).to(device)\n",
    "            y_masked = torch.masked_select(y, mask).to(device)\n",
    "\n",
    "            output_ls.append(outputs[:, :lengths])\n",
    "            target_ls.append(y[:, :lengths])\n",
    "\n",
    "            case_loss = criterion(outputs_masked, y_masked).item()\n",
    "            test_loss += case_loss\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # Flatten the test target and prediction lists\n",
    "    flat_test_target = torch.cat([t.flatten() for t in target_ls])\n",
    "    flat_test_predict = torch.cat([p.flatten() for p in output_ls])\n",
    "    pearson_r, _ = pearsonr(flat_test_target.cpu().numpy(), flat_test_predict.cpu().numpy())\n",
    "\n",
    "    # Determine the number of rows and columns for subplots\n",
    "    num_samples = len(output_ls)\n",
    "    cols = 2\n",
    "    rows = num_samples // cols + (num_samples % cols > 0)\n",
    "\n",
    "    # # Plotting\n",
    "    # plt.figure(figsize=(12, 4 * rows))\n",
    "    # for i in range(num_samples):\n",
    "    #     plt.subplot(rows, cols, i + 1)\n",
    "    #     plt.plot(output_ls[i][0].cpu().numpy(), label='Predicted')\n",
    "    #     plt.plot(target_ls[i][0].cpu().numpy(), label='Target', alpha=0.7)\n",
    "    #     plt.title(f\"Sample {i+1}\")\n",
    "    #     plt.xlabel(\"Time Steps\")\n",
    "    #     plt.ylabel(\"Values\")\n",
    "    #     plt.legend()\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    print(f'Test set: Average loss: {test_loss:.4f}, Pearson\\'s R: {pearson_r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, kernel=3, num_filters=64, num_in_channels=3, padding=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(num_in_channels, num_filters, kernel_size=kernel, padding=padding)\n",
    "        self.conv1.weight.data.uniform_(0, 0.01)\n",
    "        self.conv2 = nn.Conv1d(num_filters, 128, kernel_size=kernel, padding=padding)\n",
    "        self.conv2.weight.data.uniform_(0, 0.01)\n",
    "\n",
    "        self.conv_seq = nn.Sequential(\n",
    "            self.conv1,\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            self.conv2,\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "        )\n",
    "        conv_output_size = self._calculate_conv_output_size(max_l, kernel, padding)\n",
    "        self.fc1 = torch.nn.Linear(conv_output_size, 128)\n",
    "        init.uniform_(self.fc1.weight, -0.01, 0.01)\n",
    "\n",
    "        self.fc_seq = torch.nn.Sequential( \n",
    "            self.fc1,\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.final_layer = nn.Linear(in_features=128, out_features=max_y)\n",
    "        init.uniform_(self.final_layer.weight, -0.01, 0.01)\n",
    "\n",
    "    def _calculate_conv_output_size(self, input_length, kernel, padding):\n",
    "        size = (input_length - kernel + 2 * padding) + 1\n",
    "        size = size // 2\n",
    "        size = (size - kernel + 2 * padding) + 1\n",
    "        size = size // 2\n",
    "        return size * 128  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_seq(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_seq(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 200\n",
    "# model = CNN(kernel=3, num_filters=64).to(device)\n",
    "# total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# print(f\"Total trainable parameters in the model: {total_params}\")\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.000001, betas=(0.9, 0.999), eps=1e-08, amsgrad=True)\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# train(model, train_loader, val_loader, test_loader, criterion, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, kernel=3, num_filters=64, num_in_channels=3, padding=0, lstm_hidden_size=128, lstm_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(num_in_channels, num_filters, kernel_size=kernel, padding=padding)\n",
    "        self.conv1.weight.data.uniform_(0, 0.01)\n",
    "        self.conv2 = nn.Conv1d(num_filters, 128, kernel_size=kernel, padding=padding)\n",
    "        self.conv2.weight.data.uniform_(0, 0.01)\n",
    "\n",
    "        self.conv_seq = nn.Sequential(\n",
    "            self.conv1,\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            self.conv2,\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        conv_output_size = self._calculate_conv_output_size(max_l, kernel, padding)\n",
    "        self.lstm = nn.LSTM(input_size=conv_output_size, hidden_size=lstm_hidden_size, num_layers=lstm_layers, batch_first=True)\n",
    "\n",
    "        # Final fully connected layer\n",
    "        self.final_layer = nn.Linear(in_features=lstm_hidden_size, out_features=max_y)\n",
    "\n",
    "    def _calculate_conv_output_size(self, input_length, kernel, padding):\n",
    "        size = (input_length - kernel + 2 * padding) + 1\n",
    "        size = size // 2\n",
    "        size = (size - kernel + 2 * padding) + 1\n",
    "        size = size // 2\n",
    "        return size * 128  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN layers\n",
    "        x = self.conv_seq(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = x.unsqueeze(1)  # Adding a sequence dimension\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.final_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters in the model: 23208048\n",
      "Epoch 20, Training Loss: 5226.060302734375, Validation Loss: 1984.803257533482\n",
      "Epoch 40, Training Loss: 2311.6315185546873, Validation Loss: 330.47486986432756\n",
      "Epoch 60, Training Loss: 1298.3838012695312, Validation Loss: 115.2930521283831\n",
      "Epoch 80, Training Loss: 1040.2297119140626, Validation Loss: 265.11372443607877\n",
      "Epoch 100, Training Loss: 987.1676635742188, Validation Loss: 383.0251159667969\n",
      "Epoch 120, Training Loss: 987.4123657226562, Validation Loss: 446.49072701590404\n",
      "Epoch 140, Training Loss: 910.52626953125, Validation Loss: 471.4165834699358\n",
      "Epoch 160, Training Loss: 909.5814331054687, Validation Loss: 477.0453785487584\n",
      "Epoch 180, Training Loss: 1061.8705627441407, Validation Loss: 473.62329537527904\n",
      "Epoch 200, Training Loss: 964.45556640625, Validation Loss: 479.6702412196568\n",
      "Epoch 200, Pearson's R: 0.17960423473736697\n",
      "Test set: Average loss: 1427.8958, Pearson's R: 0.17203729363222567\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "model1 = CNNLSTM(kernel=3, num_filters=64, lstm_hidden_size=128, lstm_layers=1).to(device)\n",
    "total_params = sum(p.numel() for p in model1.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters in the model: {total_params}\")\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.01, amsgrad=True)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train(model1, train_loader, val_loader, test_loader, criterion, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Regressive  \n",
    "https://arxiv.org/pdf/1703.04122.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Offset Network (Multilayer Perceptron)\n",
    "class OffsetNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(OffsetNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
    "        self.fc1.weight.data.uniform_(0, 0.005)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.leaky_relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "# Define the Significance Network (Fully Convolutional Network)\n",
    "class SignificanceNetwork(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(SignificanceNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, max_y, kernel_size=14, dilation=113)\n",
    "        self.conv1.weight.data.uniform_(0, 0.005)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.leaky_relu(self.conv1(x))\n",
    "        return x\n",
    "\n",
    "# Define the SOCNN Model\n",
    "class SOCNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, time_steps, channels):\n",
    "        super(SOCNN, self).__init__()\n",
    "        self.time_steps = time_steps\n",
    "        self.output_dim = output_dim\n",
    "    \n",
    "        self.significance_network = SignificanceNetwork(channels).to(device)\n",
    "        self.offset_network = OffsetNetwork(input_dim, output_dim).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0] # shape = [32, 4, 1470]\n",
    "        self.W = nn.Parameter(torch.empty((batch_size, self.output_dim, self.time_steps)).uniform_(0, 0.005)).to(device)\n",
    "\n",
    "        significance = self.significance_network(x) # shape = 32, 1054, 1]\n",
    "\n",
    "        offsets = torch.stack([self.offset_network(x[:, :, i]) for i in range(self.time_steps)])\n",
    "        offsets = torch.reshape(offsets, (offsets.shape[1], offsets.shape[0], offsets.shape[2])) # shape = [32, time_step (1470), 1054]\n",
    "        \n",
    "        test = torch.bmm(self.W, offsets) # shape = [32, 1054, 1054])\n",
    "        y_hat = torch.bmm(test, significance) # shape = [32, 1054, 1]\n",
    "        y_hat = torch.reshape(y_hat, (y_hat.shape[0], y_hat.shape[2], y_hat.shape[1]))\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters in the model: 17296\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (1416). Kernel size: (1470). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\28035\\Desktop\\MIE429\\capstone_cnn\\CNN\\cnn_v3.ipynb Cell 26\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model1\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, amsgrad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train(model1, train_loader, val_loader, test_loader, criterion, optimizer, epochs)\n",
      "\u001b[1;32mc:\\Users\\28035\\Desktop\\MIE429\\capstone_cnn\\CNN\\cnn_v3.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m inputs, y \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(outputs\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mexpand(\u001b[39mlen\u001b[39m(lengths), outputs\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)) \u001b[39m<\u001b[39m lengths\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m mask \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\interpreter\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\interpreter\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\28035\\Desktop\\MIE429\\capstone_cnn\\CNN\\cnn_v3.ipynb Cell 26\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m batch_size \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m# shape = [32, 4, 1470]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mParameter(torch\u001b[39m.\u001b[39mempty((batch_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_steps))\u001b[39m.\u001b[39muniform_(\u001b[39m0\u001b[39m, \u001b[39m0.005\u001b[39m))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m significance \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignificance_network(x) \u001b[39m# shape = 32, 1054, 1]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m offsets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffset_network(x[:, :, i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_steps)])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m offsets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(offsets, (offsets\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], offsets\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], offsets\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])) \u001b[39m# shape = [32, time_step (1470), 1054]\u001b[39;00m\n",
      "File \u001b[1;32md:\\interpreter\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\interpreter\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\28035\\Desktop\\MIE429\\capstone_cnn\\CNN\\cnn_v3.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mleaky_relu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/28035/Desktop/MIE429/capstone_cnn/CNN/cnn_v3.ipynb#X41sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\interpreter\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\interpreter\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\interpreter\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32md:\\interpreter\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    307\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (1416). Kernel size: (1470). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "model1 = SOCNN(input_dim=3, output_dim=max_y, time_steps=max_l, channels=3).to(device)\n",
    "total_params = sum(p.numel() for p in model1.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters in the model: {total_params}\")\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.01, amsgrad=True)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train(model1, train_loader, val_loader, test_loader, criterion, optimizer, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
